{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "#ResNet101 on Cifar-10"
      ],
      "metadata": {
        "id": "L0DeVtxRDxd6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Import libraries\n"
      ],
      "metadata": {
        "id": "MzwMqghMlDk4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {
        "id": "i8qaKqYJkUuo"
      },
      "outputs": [],
      "source": [
        "from copy import deepcopy\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.optim import SGD,Adam,lr_scheduler\n",
        "from torch.utils.data import random_split\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data.dataset import Subset\n",
        "import torchvision\n",
        "from torchvision import transforms, models, datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Option 1 Cifar-10 Dataset original"
      ],
      "metadata": {
        "id": "BUmJYDts2sue"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_indices = torch.arange(0, 49000)\n",
        "valid_indices = torch.arange(49000, 50000)\n",
        "\n",
        "\n",
        "train_and_valid = datasets.CIFAR10(root='data', \n",
        "                                   train=True, \n",
        "                                   transform=transforms.ToTensor(),\n",
        "                                   download=True)\n",
        "\n",
        "train_dataset = Subset(train_and_valid, train_indices)\n",
        "valid_dataset = Subset(train_and_valid, valid_indices)\n",
        "\n",
        "\n",
        "test_dataset = datasets.CIFAR10(root='data', \n",
        "                                train=False, \n",
        "                                transform=transforms.ToTensor())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LTAzXTpU2cgO",
        "outputId": "138d33e0-b3b7-4e3d-9b02-939531ac3708"
      },
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Option 2 Cifar-10 Dataset with resize"
      ],
      "metadata": {
        "id": "HYSCakigEcSz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_transform = transforms.Compose([\n",
        "    transforms.Resize(224),\n",
        "    transforms.RandomHorizontalFlip(p=.40),\n",
        "    transforms.RandomRotation(30),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
        "\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.Resize(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
        "\n",
        "\n",
        "train_indices = torch.arange(0, 49000)\n",
        "valid_indices = torch.arange(49000, 50000)\n",
        "\n",
        "\n",
        "train_and_valid = datasets.CIFAR10(root='data', \n",
        "                                   train=True, \n",
        "                                   transform=train_transform,\n",
        "                                   download=True)\n",
        "\n",
        "train_dataset = Subset(train_and_valid, train_indices)\n",
        "valid_dataset = Subset(train_and_valid, valid_indices)\n",
        "\n",
        "\n",
        "test_dataset = datasets.CIFAR10(root='data', \n",
        "                                train=False, \n",
        "                                transform=test_transform)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ffAwOdVuEpvJ",
        "outputId": "d3e571e6-cb3e-4625-98e2-0d09bf1a2e07"
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Cifar10 Dataloaders"
      ],
      "metadata": {
        "id": "EDvuqOhkGkTh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader(dataset=train_dataset, \n",
        "                          batch_size=64,\n",
        "                          num_workers=8,\n",
        "                          shuffle=True,)\n",
        "\n",
        "valid_loader = DataLoader(dataset=valid_dataset, \n",
        "                          batch_size=64,\n",
        "                          num_workers=8,\n",
        "                          shuffle=False)\n",
        "\n",
        "test_loader = DataLoader(dataset=test_dataset, \n",
        "                         batch_size=64,\n",
        "                         num_workers=8,\n",
        "                         shuffle=False)\n",
        "\n",
        "\n",
        "# Checking the dataset\n",
        "for images, labels in train_loader:  \n",
        "    print('Image batch dimensions:', images.shape)\n",
        "    print('Image label dimensions:', labels.shape)\n",
        "    break\n",
        "\n",
        "for images, labels in test_loader:  \n",
        "    print('Image batch dimensions:', images.shape)\n",
        "    print('Image label dimensions:', labels.shape)\n",
        "    break\n",
        "    \n",
        "for images, labels in valid_loader:  \n",
        "    print('Image batch dimensions:', images.shape)\n",
        "    print('Image label dimensions:', labels.shape)\n",
        "    break"
      ],
      "metadata": {
        "id": "O0hZtalqGpki",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ae16b88a-233b-4286-fe84-22e646321066"
      },
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image batch dimensions: torch.Size([64, 3, 32, 32])\n",
            "Image label dimensions: torch.Size([64])\n",
            "Image batch dimensions: torch.Size([64, 3, 32, 32])\n",
            "Image label dimensions: torch.Size([64])\n",
            "Image batch dimensions: torch.Size([64, 3, 32, 32])\n",
            "Image label dimensions: torch.Size([64])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model ResNet101"
      ],
      "metadata": {
        "id": "NuJEM1XBMCCt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Model(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        base = models.resnet101(pretrained=True)\n",
        "        self.base = nn.Sequential(*list(base.children())[:-1])\n",
        "        in_features = base.fc.in_features\n",
        "        self.drop = nn.Dropout()\n",
        "        self.final = nn.Linear(in_features,10)\n",
        "    \n",
        "    def forward(self,x):\n",
        "        x = self.base(x)\n",
        "        x = self.drop(x.view(-1,self.final.in_features))\n",
        "        return self.final(x)\n",
        "    \n",
        "model = Model().cuda()"
      ],
      "metadata": {
        "id": "yiDJ3F4wLdYs"
      },
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "param_groups = [\n",
        "    {'params':model.base.parameters(),'lr':.0001},\n",
        "    {'params':model.final.parameters(),'lr':.001}\n",
        "]\n",
        "optimizer = Adam(param_groups)\n",
        "lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.1)\n",
        "states = {}"
      ],
      "metadata": {
        "id": "08TZxgVdM5Mz"
      },
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training"
      ],
      "metadata": {
        "id": "mwQxJ_kgj0uV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best_val_acc = -1000\n",
        "best_val_model = None\n",
        "for epoch in range(5):  \n",
        "    model.train(True)\n",
        "    running_loss = 0.0\n",
        "    running_acc = 0\n",
        "    for i, data in enumerate(train_loader, 0):\n",
        "        inputs, labels = data\n",
        "        inputs, labels = inputs.cuda(),labels.cuda()\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # print statistics\n",
        "        running_loss += loss.item() * inputs.size(0)\n",
        "        out = torch.argmax(outputs.detach(),dim=1)\n",
        "        assert out.shape==labels.shape\n",
        "        running_acc += (labels==out).sum().item()\n",
        "    print(f\"Train loss {epoch+1}: {running_loss/len(train_dataset)},Train Acc:{running_acc*100/len(train_dataset)}%\")\n",
        "    \n",
        "    correct = 0\n",
        "    model.train(False)\n",
        "    with torch.no_grad():\n",
        "        for inputs,labels in valid_loader:\n",
        "            out = model(inputs.cuda()).cpu()\n",
        "            out = torch.argmax(out,dim=1)\n",
        "            acc = (out==labels).sum().item()\n",
        "            correct += acc\n",
        "    print(f\"Val accuracy:{correct*100/len(valid_dataset)}%\")\n",
        "    if correct>best_val_acc:\n",
        "        best_val_acc = correct\n",
        "        best_val_model = deepcopy(model.state_dict())\n",
        "    lr_scheduler.step()\n",
        "    \n",
        "print('Finished Training')  "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5fI5pBFkNEih",
        "outputId": "9f58a5be-948f-491b-ea10-60675f0b65cf"
      },
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 1: 0.9841294645095358,Train Acc:66.21632653061225%\n",
            "Val accuracy:77.5%\n",
            "Train loss 2: 0.44831477696555,Train Acc:84.88979591836734%\n",
            "Val accuracy:82.0%\n",
            "Train loss 3: 0.3463536539077759,Train Acc:88.5%\n",
            "Val accuracy:82.0%\n",
            "Train loss 4: 0.3371592799522439,Train Acc:88.53877551020408%\n",
            "Val accuracy:82.4%\n",
            "Train loss 5: 0.3296855830100118,Train Acc:88.90612244897959%\n",
            "Val accuracy:82.0%\n",
            "Finished Training\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Testing"
      ],
      "metadata": {
        "id": "i5tFNSIEj459"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "correct = 0\n",
        "model.load_state_dict(best_val_model)\n",
        "model.train(False)\n",
        "with torch.no_grad():\n",
        "    for inputs,labels in test_loader:\n",
        "        out = model(inputs.cuda()).cpu()\n",
        "        out = torch.argmax(out,dim=1)\n",
        "        acc = (out==labels).sum().item()\n",
        "        \n",
        "        correct += acc\n",
        "print(f\"Test accuracy: {correct*100/len(test_dataset)}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kidOn5c7Oa9r",
        "outputId": "86c3cacf-3fbd-4381-e8a3-d1f9c790d58d"
      },
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy: 82.07%\n"
          ]
        }
      ]
    }
  ]
}