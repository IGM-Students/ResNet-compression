{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "#ResNet101 on Cifar-10"
      ],
      "metadata": {
        "id": "L0DeVtxRDxd6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Import libraries\n"
      ],
      "metadata": {
        "id": "MzwMqghMlDk4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "id": "i8qaKqYJkUuo"
      },
      "outputs": [],
      "source": [
        "from copy import deepcopy\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.optim import SGD,Adam,lr_scheduler\n",
        "from torch.utils.data import random_split\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data.dataset import Subset\n",
        "import torchvision\n",
        "from torchvision import transforms, models, datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Cifar-10 Dataset"
      ],
      "metadata": {
        "id": "HYSCakigEcSz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_indices = torch.arange(0, 49000)\n",
        "valid_indices = torch.arange(49000, 50000)\n",
        "\n",
        "\n",
        "train_and_valid = datasets.CIFAR10(root='data', \n",
        "                                   train=True, \n",
        "                                   transform=transforms.ToTensor(),\n",
        "                                   download=True)\n",
        "\n",
        "train_dataset = Subset(train_and_valid, train_indices)\n",
        "valid_dataset = Subset(train_and_valid, valid_indices)\n",
        "\n",
        "\n",
        "test_dataset = datasets.CIFAR10(root='data', \n",
        "                                train=False, \n",
        "                                transform=transforms.ToTensor())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ffAwOdVuEpvJ",
        "outputId": "d848f665-3e23-403c-fb2b-6586c95d578b"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Cifar10 Dataloaders"
      ],
      "metadata": {
        "id": "EDvuqOhkGkTh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader(dataset=train_dataset, \n",
        "                          batch_size=64,\n",
        "                          num_workers=8,\n",
        "                          shuffle=True)\n",
        "\n",
        "valid_loader = DataLoader(dataset=valid_dataset, \n",
        "                          batch_size=64,\n",
        "                          num_workers=8,\n",
        "                          shuffle=False)\n",
        "\n",
        "test_loader = DataLoader(dataset=test_dataset, \n",
        "                         batch_size=64,\n",
        "                         num_workers=8,\n",
        "                         shuffle=False)"
      ],
      "metadata": {
        "id": "O0hZtalqGpki"
      },
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model ResNet101"
      ],
      "metadata": {
        "id": "NuJEM1XBMCCt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Model(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        base = models.resnet101(pretrained=True)\n",
        "        self.base = nn.Sequential(*list(base.children())[:-1])\n",
        "        in_features = base.fc.in_features\n",
        "        self.drop = nn.Dropout()\n",
        "        self.final = nn.Linear(in_features,10)\n",
        "    \n",
        "    def forward(self,x):\n",
        "        x = self.base(x)\n",
        "        x = self.drop(x.view(-1,self.final.in_features))\n",
        "        return self.final(x)\n",
        "    \n",
        "model = Model().cuda()"
      ],
      "metadata": {
        "id": "yiDJ3F4wLdYs"
      },
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "param_groups = [\n",
        "    {'params':model.base.parameters(),'lr':.0001},\n",
        "    {'params':model.final.parameters(),'lr':.001}\n",
        "]\n",
        "optimizer = Adam(param_groups)\n",
        "lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.1)\n",
        "states = {}"
      ],
      "metadata": {
        "id": "08TZxgVdM5Mz"
      },
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training"
      ],
      "metadata": {
        "id": "mwQxJ_kgj0uV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best_val_acc = -1000\n",
        "best_val_model = None\n",
        "for epoch in range(5):  \n",
        "    model.train(True)\n",
        "    running_loss = 0.0\n",
        "    running_acc = 0\n",
        "    for i, data in enumerate(train_loader, 0):\n",
        "        inputs, labels = data\n",
        "        inputs, labels = inputs.cuda(),labels.cuda()\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # print statistics\n",
        "        running_loss += loss.item() * inputs.size(0)\n",
        "        out = torch.argmax(outputs.detach(),dim=1)\n",
        "        assert out.shape==labels.shape\n",
        "        running_acc += (labels==out).sum().item()\n",
        "    print(f\"Train loss {epoch+1}: {running_loss/len(train_dataset)},Train Acc:{running_acc*100/len(train_dataset)}%\")\n",
        "    \n",
        "    correct = 0\n",
        "    model.train(False)\n",
        "    with torch.no_grad():\n",
        "        for inputs,labels in valid_loader:\n",
        "            out = model(inputs.cuda()).cpu()\n",
        "            out = torch.argmax(out,dim=1)\n",
        "            acc = (out==labels).sum().item()\n",
        "            correct += acc\n",
        "    print(f\"Val accuracy:{correct*100/len(valid_dataset)}%\")\n",
        "    if correct>best_val_acc:\n",
        "        best_val_acc = correct\n",
        "        best_val_model = deepcopy(model.state_dict())\n",
        "    lr_scheduler.step()\n",
        "    \n",
        "print('Finished Training')  "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5fI5pBFkNEih",
        "outputId": "c588df65-31a4-442f-bac5-46d7bc690333"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 1: 0.9817252762560942,Train Acc:66.42244897959183%\n",
            "Val accuracy:76.8%\n",
            "Train loss 2: 0.44645514609862347,Train Acc:85.01020408163265%\n",
            "Val accuracy:82.3%\n",
            "Train loss 3: 0.3447384761279943,Train Acc:88.27755102040817%\n",
            "Val accuracy:81.9%\n",
            "Train loss 4: 0.32756214544724443,Train Acc:88.91836734693878%\n",
            "Val accuracy:82.4%\n",
            "Train loss 5: 0.32074569557151017,Train Acc:89.1%\n",
            "Val accuracy:82.1%\n",
            "Finished Training\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Testing"
      ],
      "metadata": {
        "id": "i5tFNSIEj459"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "correct = 0\n",
        "model.load_state_dict(best_val_model)\n",
        "model.train(False)\n",
        "with torch.no_grad():\n",
        "    for inputs,labels in test_loader:\n",
        "        out = model(inputs.cuda()).cpu()\n",
        "        out = torch.argmax(out,dim=1)\n",
        "        acc = (out==labels).sum().item()\n",
        "        \n",
        "        correct += acc\n",
        "print(f\"Test accuracy: {correct*100/len(test_dataset)}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kidOn5c7Oa9r",
        "outputId": "c16f489b-ec36-4092-ba9b-a1bddc938835"
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy: 82.45%\n"
          ]
        }
      ]
    }
  ]
}